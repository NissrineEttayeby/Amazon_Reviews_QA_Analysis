{"cells":[{"cell_type":"markdown","metadata":{"id":"2WkgRCG-bZuU"},"source":["# <h1 align='center'>  Amazon question/answer Classification. </h1>"]},{"cell_type":"markdown","metadata":{"id":"r_baENHybZuY"},"source":["### OBJECTIF :"]},{"cell_type":"markdown","metadata":{"id":"eQ9xGspNbZuZ"},"source":["L'objectif de ce projet est de réaliser des classifications automatiques des données de questions-réponses issues de la base de données Amazon afin d'examiner la pertinence des groupes obtenus. En d'autres termes, l'objectif est de regrouper les questions-réponses en fonction de leurs caractéristiques communes, en utilisant des techniques d'apprentissage automatique, et d'évaluer la qualité de ces groupes formés."]},{"cell_type":"markdown","metadata":{"id":"fvzEBl2AbZua"},"source":["### Data Description :"]},{"cell_type":"markdown","metadata":{"id":"8SABgkQZbZub"},"source":["Ces ensembles de données contiennent des questions et des réponses sur les produits de l'ensemble de données Amazon ci-dessus.\n","\n","- **Questions :** L'ensemble de données comprend environ 1,48 million de questions.\n","- **Réponses :** Il y a environ 4 019 744 réponses correspondant aux questions.\n","- **Questions avec oui/non étiquetées :** Sur l'ensemble des questions, environ 309 419 sont étiquetées comme des questions binaires (oui/non).\n","- **Nombre de produits uniques avec des questions :** L'ensemble de données comprend des questions relatives à 191 185 produits uniques.\n","- **Métadonnées :** L'ensemble de données inclut les métadonnées suivantes pour chaque question et réponse :\n","- **Texte de la question et de la réponse :** Le texte réel de la question et de sa réponse correspondante.\n","- **Étiquette de question binaire :** Indique si la question est binaire (oui/non) ou non, et si oui, si elle a une réponse oui/non.\n","- **Horodatage :** Informations relatives au temps, comme la date de la question et de la réponse.\n","- **ID du produit :** Ce champ fournit une référence au produit correspondant dans l'ensemble de données des évaluations, permettant ainsi une analyse ultérieure ou une intégration avec d'autres ensembles de données d'Amazon.\n","Ces informations nous donnent un aperçu de la structure de l'ensemble de données et du nombre de questions, réponses, produits uniques et questions binaires étiquetées qu'il contient.\n"]},{"cell_type":"markdown","metadata":{"id":"ZwJqaG8-bZuc"},"source":["### Data Processing :"]},{"cell_type":"markdown","metadata":{"id":"fLcqRZ4GbZud"},"source":["La fonction **parse(path)** utilisée pour lire un fichier compressé au format GZIP et extraire les données ligne par ligne. "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"_Ll94NO68Rpu","executionInfo":{"status":"ok","timestamp":1686486504145,"user_tz":-60,"elapsed":5,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["def parse(path):\n","  g = gzip.open(path, 'r')\n","  for l in g:\n","    yield eval(l)"]},{"cell_type":"markdown","metadata":{"id":"tZF704ZobZug"},"source":["Le code utilise la fonction **parse(path)** pour lire un fichier compressé GZIP contenant des données de questions-réponses d'Amazon au format JSON, puis écrit ces données dans un fichier de sortie au format JSON."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"xO9uBode8v8T","executionInfo":{"status":"ok","timestamp":1686486564671,"user_tz":-60,"elapsed":3560,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["import json\n","import gzip\n","\n","def parse(path):\n","  g = gzip.open(path, 'r')\n","  for l in g:\n","    yield json.dumps(eval(l))\n","\n","f = open(\"output.strict\", 'w')\n","for l in parse(\"/content/drive/MyDrive/qa_Beauty.json.gz\"):\n","  f.write(l + '\\n')"]},{"cell_type":"markdown","metadata":{"id":"RtvjpHMbbZuh"},"source":["Le code utilise la fonction **parse(path)** pour lire un fichier compressé GZIP contenant des données de questions-réponses d'Amazon, puis convertit ces données en un objet DataFrame de pandas."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"u3l7llfq-E6v","executionInfo":{"status":"ok","timestamp":1686486570026,"user_tz":-60,"elapsed":1846,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["import gzip\n","import pandas as pd\n","\n","def parse(path):\n","  g = gzip.open(path, 'rb')\n","  for l in g:\n","    yield eval(l)\n","\n","def getDF(path):\n","  i = 0\n","  df = {}\n","  for d in parse(path):\n","    df[i] = d\n","    i += 1\n","  return pd.DataFrame.from_dict(df, orient='index')\n","\n","df = getDF('/content/drive/MyDrive/qa_Beauty.json.gz')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1686486571898,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"5vAaWNn7-VGX","outputId":"cced5c9b-30b1-4ed8-9e2a-a9e42647b0fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      questionType        asin    answerTime  \\\n","0           yes/no  602260074X   10 days ago   \n","1           yes/no  602260074X   Mar 3, 2015   \n","2           yes/no  602260074X  Dec 30, 2014   \n","3       open-ended  602260074X  Jul 13, 2014   \n","4           yes/no  602260074X  May 21, 2014   \n","...            ...         ...           ...   \n","42417       yes/no  B00L5JHZJO   Jul 2, 2014   \n","42418       yes/no  B00L5JHZJO   Jul 2, 2014   \n","42419   open-ended  B00L5JHZJO   Jul 2, 2014   \n","42420   open-ended  B00L5JHZJO   Jul 2, 2014   \n","42421   open-ended  B00L5JHZJO   Jul 2, 2014   \n","\n","                                                question answerType  \\\n","0               can you fit make up brushes in the trays          Y   \n","1                         Can you move all the dividers?          ?   \n","2                     is the surface in side the smooth?          Y   \n","3               How deep do the extending trays measure?        NaN   \n","4      Can bottles of nail polish stand upright in th...          ?   \n","...                                                  ...        ...   \n","42417  I find myself with rough cuticles right around...          Y   \n","42418                        is it good for nail beauty?          ?   \n","42419      how can i use it for Topical Use on Dry Hair?        NaN   \n","42420        how can i use it for In-Shower Application?        NaN   \n","42421    how can i use it for Deep Conditioning Session?        NaN   \n","\n","                                                  answer      unixTime  \n","0      yes it comes with adjustable dividers, you can...           NaN  \n","1           yes,all the provided dividers are adjustable  1.425370e+09  \n","2                                                    Yes  1.419926e+09  \n","3      Hi there, Not too deep. Maybe like an inch dee...  1.405235e+09  \n","4                     No. We just tried it and it won't.  1.400656e+09  \n","...                                                  ...           ...  \n","42417  Yes, you can. In the evening before you go to ...  1.404284e+09  \n","42418  I would say it's good for cuticles. I can't sa...  1.404284e+09  \n","42419  A little goes a long way! A drop or two, depen...  1.404284e+09  \n","42420  Application during shower takes less time. Aft...  1.404284e+09  \n","42421  You can use it as a pre-shampoo treatment, whe...  1.404284e+09  \n","\n","[42422 rows x 7 columns]"],"text/html":["\n","  <div id=\"df-ae9e2501-cb54-4800-b030-4a1a6e0d4ce4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>questionType</th>\n","      <th>asin</th>\n","      <th>answerTime</th>\n","      <th>question</th>\n","      <th>answerType</th>\n","      <th>answer</th>\n","      <th>unixTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yes/no</td>\n","      <td>602260074X</td>\n","      <td>10 days ago</td>\n","      <td>can you fit make up brushes in the trays</td>\n","      <td>Y</td>\n","      <td>yes it comes with adjustable dividers, you can...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>yes/no</td>\n","      <td>602260074X</td>\n","      <td>Mar 3, 2015</td>\n","      <td>Can you move all the dividers?</td>\n","      <td>?</td>\n","      <td>yes,all the provided dividers are adjustable</td>\n","      <td>1.425370e+09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>yes/no</td>\n","      <td>602260074X</td>\n","      <td>Dec 30, 2014</td>\n","      <td>is the surface in side the smooth?</td>\n","      <td>Y</td>\n","      <td>Yes</td>\n","      <td>1.419926e+09</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>open-ended</td>\n","      <td>602260074X</td>\n","      <td>Jul 13, 2014</td>\n","      <td>How deep do the extending trays measure?</td>\n","      <td>NaN</td>\n","      <td>Hi there, Not too deep. Maybe like an inch dee...</td>\n","      <td>1.405235e+09</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>yes/no</td>\n","      <td>602260074X</td>\n","      <td>May 21, 2014</td>\n","      <td>Can bottles of nail polish stand upright in th...</td>\n","      <td>?</td>\n","      <td>No. We just tried it and it won't.</td>\n","      <td>1.400656e+09</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>42417</th>\n","      <td>yes/no</td>\n","      <td>B00L5JHZJO</td>\n","      <td>Jul 2, 2014</td>\n","      <td>I find myself with rough cuticles right around...</td>\n","      <td>Y</td>\n","      <td>Yes, you can. In the evening before you go to ...</td>\n","      <td>1.404284e+09</td>\n","    </tr>\n","    <tr>\n","      <th>42418</th>\n","      <td>yes/no</td>\n","      <td>B00L5JHZJO</td>\n","      <td>Jul 2, 2014</td>\n","      <td>is it good for nail beauty?</td>\n","      <td>?</td>\n","      <td>I would say it's good for cuticles. I can't sa...</td>\n","      <td>1.404284e+09</td>\n","    </tr>\n","    <tr>\n","      <th>42419</th>\n","      <td>open-ended</td>\n","      <td>B00L5JHZJO</td>\n","      <td>Jul 2, 2014</td>\n","      <td>how can i use it for Topical Use on Dry Hair?</td>\n","      <td>NaN</td>\n","      <td>A little goes a long way! A drop or two, depen...</td>\n","      <td>1.404284e+09</td>\n","    </tr>\n","    <tr>\n","      <th>42420</th>\n","      <td>open-ended</td>\n","      <td>B00L5JHZJO</td>\n","      <td>Jul 2, 2014</td>\n","      <td>how can i use it for In-Shower Application?</td>\n","      <td>NaN</td>\n","      <td>Application during shower takes less time. Aft...</td>\n","      <td>1.404284e+09</td>\n","    </tr>\n","    <tr>\n","      <th>42421</th>\n","      <td>open-ended</td>\n","      <td>B00L5JHZJO</td>\n","      <td>Jul 2, 2014</td>\n","      <td>how can i use it for Deep Conditioning Session?</td>\n","      <td>NaN</td>\n","      <td>You can use it as a pre-shampoo treatment, whe...</td>\n","      <td>1.404284e+09</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>42422 rows × 7 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae9e2501-cb54-4800-b030-4a1a6e0d4ce4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ae9e2501-cb54-4800-b030-4a1a6e0d4ce4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ae9e2501-cb54-4800-b030-4a1a6e0d4ce4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["df"]},{"cell_type":"markdown","metadata":{"id":"tbk2xwJbHdUQ"},"source":["- 'questionType': Il s'agit du type de question posée. Dans cet exemple, il est défini comme 'yes/no', ce qui signifie que la question peut être répondu par oui ou non.\n","\n","- 'asin': C'est un identifiant unique pour le produit auquel la question et la réponse se réfèrent. Il est utilisé pour identifier de manière unique le produit dans la base de données.\n","\n","- 'answerTime': Il indique le moment où la réponse a été donnée. Dans le premier exemple, il est spécifié comme '10 days ago', ce qui signifie que la réponse a été donnée il y a 10 jours à partir du moment où les données ont été collectées.\n","\n","- 'unixTime': C'est une autre représentation temporelle de la réponse, donnée sous forme de nombre entier représentant le nombre de secondes écoulées depuis le 1er janvier 1970 à minuit UTC.\n","\n","- 'question': Il s'agit de la question posée par l'utilisateur concernant le produit.\n","\n","- 'answerType': Cela représente le type de réponse donnée à la question. Dans le premier exemple, il est défini comme 'Y', ce qui peut signifier que la réponse est positive ou affirmative.\n","\n","- 'answer': C'est la réponse à la question posée par l'utilisateur."]},{"cell_type":"markdown","metadata":{"id":"sWiUY7ThbZuj"},"source":["### Spark Session :"]},{"cell_type":"markdown","metadata":{"id":"mV5doSQsbZuk"},"source":["utilise PySpark pour créer une session Spark."]},{"cell_type":"code","source":["pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SjAa0Gobw4w","executionInfo":{"status":"ok","timestamp":1686486645827,"user_tz":-60,"elapsed":50900,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}},"outputId":"fb5f3909-8dd3-4ade-9c6e-c3d15f4f5350"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=f28c03d4934768debf2cca8688f343a3e5a6fac0b5aa75d1a5bae219baf2a5b1\n","  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.0\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dqcgV7pf_kRu","executionInfo":{"status":"ok","timestamp":1686486663488,"user_tz":-60,"elapsed":15522,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n"]},{"cell_type":"markdown","metadata":{"id":"LJykb_wWbZuk"},"source":["**spark = SparkSession.builder.getOrCreate()** crée une instance de SparkSession. **SparkSession** est l'entrée principale pour l'utilisation des fonctionnalités de Spark SQL. La méthode **builder** est utilisée pour configurer la session Spark, et **getOrCreate(**) permet de récupérer une session existante ou d'en créer une nouvelle si aucune session n'existe."]},{"cell_type":"markdown","metadata":{"id":"nFABgc57bZuk"},"source":["### Spark DataFrame :"]},{"cell_type":"markdown","metadata":{"id":"rxWjws22bZul"},"source":["convertit le DataFrame pandas (df) en un DataFrame Spark, puis effectue des opérations Spark sur ce DataFrame."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11997,"status":"ok","timestamp":1686486680046,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"3NIFwB8T-WXY","outputId":"079cc66d-f4ec-421b-b5e0-88b2b3c9525b"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","|questionType|      asin|  answerTime|            question|answerType|              answer|   unixTime|\n","+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","|      yes/no|602260074X| 10 days ago|can you fit make ...|         Y|yes it comes with...|        NaN|\n","|      yes/no|602260074X| Mar 3, 2015|Can you move all ...|         ?|yes,all the provi...|1.4253696E9|\n","|      yes/no|602260074X|Dec 30, 2014|is the surface in...|         Y|                 Yes|1.4199264E9|\n","|  open-ended|602260074X|Jul 13, 2014|How deep do the e...|       NaN|Hi there, Not too...|1.4052348E9|\n","|      yes/no|602260074X|May 21, 2014|Can bottles of na...|         ?|No. We just tried...|1.4006556E9|\n","|  open-ended|602260074X|Feb 25, 2014|what are the Weight?|       NaN|Light box. Carry ...|1.3933152E9|\n","|  open-ended|602260074X| Dec 3, 2013|What are the dime...|       NaN|I'm not sure but ...|1.3860576E9|\n","|  open-ended|602260074X|Jul 23, 2013|What are the tray...|       NaN|There are 4 trays...|1.3745628E9|\n","|  open-ended|7800558258| 18 days ago|how can I get a p...|       NaN|                good|        NaN|\n","|  open-ended|7800558258|Feb 28, 2015|I have used the P...|       NaN|Thanks for your q...|1.4251104E9|\n","|  open-ended|7800558258|May 28, 2014|goodnight crompre...|       NaN|I own this unit a...|1.4012604E9|\n","|      yes/no|7800558258|Jan 30, 2014|Does it work for ...|         N|No it doesn't the...|1.3910688E9|\n","|      yes/no|7800558258| Nov 6, 2013|does it come with...|         Y|                 Yes|1.3837248E9|\n","|  open-ended|9788071813|Jun 10, 2014|how i know if the...|       NaN|Why are you askin...|1.4023836E9|\n","|  open-ended|9788071813|Apr 23, 2014|Is this product i...|       NaN|Yes, it's perfect...|1.3982364E9|\n","|      yes/no|9788071813|Apr 23, 2014|Is it in an origi...|         ?|s est en el paque...|1.3982364E9|\n","|  open-ended|B00004TUBL|Aug 15, 2013|how hard is it to...|       NaN|It's very easy to...|  1.37655E9|\n","|  open-ended|B00004TUBL| Dec 6, 2014|Can I mount this ...|       NaN|I just used the c...|1.4178528E9|\n","|      yes/no|B00004TUBL|Jun 12, 2014|Are the chambers ...|         ?|I have the four-c...|1.4025564E9|\n","|  open-ended|B00004TUBL|Oct 10, 2014|My spouse is worr...|       NaN|It opens easy to ...|1.4129244E9|\n","+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["# Convert the pandas DataFrame to a Spark DataFrame\n","spark_df = spark.createDataFrame(df)\n","\n","# Perform Spark operations on the converted DataFrame\n","# For example, you can show the first few rows\n","spark_df.show()\n"]},{"cell_type":"markdown","metadata":{"id":"YcEGAHDrbZul"},"source":["La sortie affichée montre les premières lignes du DataFrame Spark spark_df avec des colonnes telles que questionType, asin, answerTime, question, answer, et unixTime. Chaque ligne correspond à une question-réponse d'Amazon."]},{"cell_type":"markdown","metadata":{"id":"3RvFRBMsbZum"},"source":["### Data Cleaning :"]},{"cell_type":"markdown","metadata":{"id":"iqd4TVKJbZum"},"source":["Le code utilise des fonctions de Spark SQL pour compter le nombre de valeurs manquantes (NaN) dans chaque colonne du DataFrame Spark spark_df et affiche ces comptages."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14396,"status":"ok","timestamp":1686486722470,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"UNBgBL58_xF_","outputId":"bcb4ebfb-7a4a-4dfd-e590-33fa2b257622"},"outputs":[{"output_type":"stream","name":"stdout","text":["Column 'questionType': 0 NaN values\n","Column 'asin': 0 NaN values\n","Column 'answerTime': 0 NaN values\n","Column 'question': 0 NaN values\n","Column 'answerType': 24331 NaN values\n","Column 'answer': 0 NaN values\n","Column 'unixTime': 1632 NaN values\n"]}],"source":["from pyspark.sql.functions import col, isnan, sum as spark_sum\n","\n","# Iterate over each column and count the NaN values\n","nan_counts = [(column, spark_df.select(spark_sum(isnan(col(column)).cast(\"integer\"))).collect()[0][0]) for column in spark_df.columns]\n","\n","# Print the NaN counts for each column\n","for column, count in nan_counts:\n","    print(f\"Column '{column}': {count} NaN values\")\n"]},{"cell_type":"markdown","metadata":{"id":"AaVEvMvIbZum"},"source":["En exécutant ce code, nous obtiendrez l'affichage des comptages de valeurs NaN pour chaque colonne du DataFrame Spark spark_df. Cela peut nous aider à identifier les colonnes avec des valeurs manquantes dans nos données de questions-réponses d'Amazon."]},{"cell_type":"markdown","metadata":{"id":"z_r060O3bZum"},"source":["### Data Transformation :"]},{"cell_type":"markdown","metadata":{"id":"InBLdVhSbZun"},"source":["Le code définit deux dictionnaires : **contractions** et **special_characters_dict**. Ces dictionnaires sont utilisés pour standardiser et rendre le texte plus formel et cohérent dans le jeu de données."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jOPVS57JkgIK","executionInfo":{"status":"ok","timestamp":1686486726901,"user_tz":-60,"elapsed":5,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["#  Removing contractions to standardize the text and make it more formal and consistent throughout the dataset.\n","contractions = { \n","    \"ain't\": \"am not\",\n","    \"aren't\": \"are not\",\n","    \"can't\": \"can not\",\n","    \"can't've\": \"can not have\",\n","    \"'cause\": \"because\",\n","    \"could've\": \"could have\",\n","    \"couldn't\": \"could not\",\n","    \"couldn't've\": \"could not have\",\n","    \"didn't\": \"did not\",\n","    \"doesn't\": \"does not\",\n","    \"don't\": \"do not\",\n","    \"hadn't\": \"had not\",\n","    \"hadn't've\": \"had not have\",\n","    \"hasn't\": \"has not\",\n","    \"haven't\": \"have not\",\n","    \"he'd\": \"he would\",\n","    \"he'd've\": \"he would have\",\n","    \"he'll\": \"he will\",\n","    \"he'll've\": \"he will have\",\n","    \"he's\": \"he is\",\n","    \"how'd\": \"how did\",\n","    \"how'd'y\": \"how do you\",\n","    \"how'll\": \"how will\",\n","    \"how's\": \"how is\",\n","    \"i'd\": \"i would\",\n","    \"i'd've\": \"i would have\",\n","    \"i'll\": \"i will\",\n","    \"i'll've\": \"i will have\",\n","    \"i'm\": \"i am\",\n","    \"i've\": \"i have\",\n","    \"isn't\": \"is not\",\n","    \"it'd\": \"it would\",\n","    \"it'd've\": \"it would have\",\n","    \"it'll\": \"it will\",\n","    \"it'll've\": \"it will have\",\n","    \"it's\": \"it is\",\n","    \"let's\": \"let us\",\n","    \"ma'am\": \"madam\",\n","    \"mayn't\": \"may not\",\n","    \"might've\": \"might have\",\n","    \"mightn't\": \"might not\",\n","    \"mightn't've\": \"might not have\",\n","    \"must've\": \"must have\",\n","    \"mustn't\": \"must not\",\n","    \"mustn't've\": \"must not have\",\n","    \"needn't\": \"need not\",\n","    \"needn't've\": \"need not have\",\n","    \"o'clock\": \"of the clock\",\n","    \"oughtn't\": \"ought not\",\n","    \"oughtn't've\": \"ought not have\",\n","    \"shan't\": \"shall not\",\n","    \"sha'n't\": \"shall not\",\n","    \"shan't've\": \"shall not have\",\n","    \"she'd\": \"she would\",\n","    \"she'd've\": \"she would have\",\n","    \"she'll\": \"she will\",\n","    \"she'll've\": \"she will have\",\n","    \"she's\": \"she is\",\n","    \"should've\": \"should have\",\n","    \"shouldn't\": \"should not\",\n","    \"shouldn't've\": \"should not have\",\n","    \"so've\": \"so have\",\n","    \"so's\": \"so as\",\n","    \"that'd\": \"that would\",\n","    \"that'd've\": \"that would have\",\n","    \"that's\": \"that is\",\n","    \"there'd\": \"there would\",\n","    \"there'd've\": \"there would have\",\n","    \"there's\": \"there is\",\n","    \"they'd\": \"they would\",\n","    \"they'd've\": \"they would have\",\n","    \"they'll\": \"they will\",\n","    \"they'll've\": \"they will have\",\n","    \"they're\": \"they are\",\n","    \"they've\": \"they have\",\n","    \"to've\": \"to have\",\n","    \"wasn't\": \"was not\",\n","    \"we'd\": \"we would\",\n","    \"we'd've\": \"we would have\",\n","    \"we'll\": \"we will\",\n","    \"we'll've\": \"we will have\",\n","    \"we're\": \"we are\",\n","    \"we've\": \"we have\",\n","    \"weren't\": \"were not\",\n","    \"what'll\": \"what will\",\n","    \"what'll've\": \"what will have\",\n","    \"what're\": \"what are\",\n","    \"what's\": \"what is\",\n","    \"what've\": \"what have\",\n","    \"when's\": \"when is\",\n","    \"when've\": \"when have\",\n","    \"where'd\": \"where did\",\n","    \"where's\": \"where is\",\n","    \"where've\": \"where have\",\n","    \"who'll\": \"who will\",\n","    \"who'll've\": \"who will have\",\n","    \"who's\": \"who is\",\n","    \"who've\": \"who have\",\n","    \"why's\": \"why is\",\n","    \"why've\": \"why have\",\n","    \"will've\": \"will have\",\n","    \"won't\": \"will not\",\n","    \"won't've\": \"will not have\",\n","    \"would've\": \"would have\",\n","    \"wouldn't\": \"would not\",\n","    \"wouldn't've\": \"would not have\",\n","    \"y'all\": \"you all\",\n","    \"y'all'd\": \"you all would\",\n","    \"y'all'd've\": \"you all would have\",\n","    \"y'all're\": \"you all are\",\n","    \"y'all've\": \"you all have\",\n","    \"you'd\": \"you would\",\n","    \"you'd've\": \"you would have\",\n","    \"you'll\": \"you will\",\n","    \"you'll've\": \"you will have\",\n","    \"you're\": \"you are\",\n","    \"you've\": \"you have\"\n","    }\n","\n","# Removing special characters helps to standardize the text by eliminating non-alphanumeric characters.     \n","special_characters_dict = {\n","    \"%\": \" percentage \",\n","    \"€\": \" euro \",\n","    \"&\": \" ampersand \",\n","    '₹':' rupee ',\n","    '@':' at ' ,\n","    '$':' dollar '\n","}\n","\n","\n","# # Converting special characters to their textual representations helps to enhance the semantic clarity of the text. \n","\n","special_number={\n","    ',000,000,000 ': 'b ',\n","    ',000,000 ': 'm ',\n","    ',000 ': 'k '  \n","}\n"]},{"cell_type":"markdown","metadata":{"id":"RXbejlpdbZup"},"source":["### Traitement des donnees"]},{"cell_type":"markdown","metadata":{"id":"ZqojurQsbZup"},"source":["Nous avons téléchargé les ressources nécessaires de **NLTK**. La ressource **'punkt'** fournit le support de la tokenisation, et la ressource **'wordnet'** donne accès à la base de données lexicale WordNet."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2757,"status":"ok","timestamp":1686486732986,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"PVuj8fOnn4g9","outputId":"03d65ebc-d11f-471f-ec7f-43be00286696"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}],"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')"]},{"cell_type":"markdown","metadata":{"id":"H9vhsiMgbZuq"},"source":["Nous avons créé des fonctions de prétraitement du texte qui effectuent plusieurs étapes essentielles pour nettoyer et normaliser nos données. "]},{"cell_type":"code","execution_count":18,"metadata":{"id":"aqn1Q88lkgKI","executionInfo":{"status":"ok","timestamp":1686486797209,"user_tz":-60,"elapsed":578,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["import re\n","from bs4 import BeautifulSoup\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","\n","def lemmatize_sentence(sentence):\n","    lemmatizer = WordNetLemmatizer()\n","    tokens = word_tokenize(sentence)\n","    #'v' spécifie que nous souhaitons lemmatiser les mots comme des verbes. \n","    lemmatized_tokens = [lemmatizer.lemmatize(token, 'v') for token in tokens]\n","    lemmatized_sentence = ' '.join(lemmatized_tokens)\n","    return lemmatized_sentence\n","\n","def preprocess(text):\n","    # Convert text to lowercase and remove leading/trailing spaces\n","    text = str(text).lower().strip()\n","    \n","    # Convert special numerical representations\n","    text = re.sub(r'([0-9]+)000000000', r'\\1b', text)\n","    text = re.sub(r'([0-9]+)000000', r'\\1m', text)\n","    text = re.sub(r'([0-9]+)000', r'\\1k', text)\n","    \n","    # Expand contractions\n","    text_decontracted = []\n","    for word in text.split():\n","        if word in contractions:\n","            word = contractions[word]\n","        text_decontracted.append(word)\n","    text = ' '.join(text_decontracted)\n","    \n","    # Replace special characters with their textual representations\n","    text_special_characters_dict = []\n","    for word in text.split():\n","        if word in special_characters_dict:\n","            word = special_characters_dict[word]\n","        text_special_characters_dict.append(word)\n","    text = ' '.join(text_special_characters_dict)\n","    \n","    # Remove HTML tags\n","    text = BeautifulSoup(text, 'html.parser').get_text()\n","    \n","    # Remove punctuation\n","    pattern = re.compile('\\W')\n","    text = re.sub(pattern, ' ', text).strip()\n","    \n","    # Lemmatize words\n","    text = lemmatize_sentence(text)\n","    \n","    return text"]},{"cell_type":"markdown","metadata":{"id":"bhUC3JmJbZur"},"source":["L'ensemble de ces étapes de prétraitement permet de nettoyer et de normaliser les données textuelles, ce qui facilite leur analyse et leur utilisation ultérieure. "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":2741,"status":"ok","timestamp":1686486803523,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"uM19cRuOkgNG","outputId":"9df4de75-1148-40ff-fc3c-9e44d891fed9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'i have already be not do'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}],"source":["# Example:\n","preprocess(\"I've already! wasn't <b>done</b>?\")"]},{"cell_type":"markdown","metadata":{"id":"hiW2-urhbZur"},"source":["Le code permet d'appliquer la fonction preprocess en tant que fonction définie par l'utilisateur (UDF) sur les colonnes \"question\" et \"answer\" du DataFrame Spark spark_df. La fonction preprocess_udf est créée à l'aide de la fonction udf() du module pyspark.sql.functions."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"QYscLa2SkgP7","executionInfo":{"status":"ok","timestamp":1686486805811,"user_tz":-60,"elapsed":275,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["from pyspark.sql.functions import udf\n","\n","# Define a UDF from the preprocess function\n","preprocess_udf = udf(preprocess)\n","\n","# Apply the UDF to the 'question' and 'answer' columns\n","spark_df = spark_df.withColumn('question', preprocess_udf(spark_df['question']))\n","spark_df = spark_df.withColumn('answer', preprocess_udf(spark_df['answer']))\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4689,"status":"ok","timestamp":1686486813206,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"23ULGAtRkgUX","outputId":"5c03fef1-2b39-483c-956f-ce5d7f2ea0df"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","|questionType|      asin|  answerTime|            question|answerType|              answer|   unixTime|\n","+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","|      yes/no|602260074X| 10 days ago|can you fit make ...|         Y|yes it come with ...|        NaN|\n","|      yes/no|602260074X| Mar 3, 2015|can you move all ...|         ?|yes all the provi...|1.4253696E9|\n","|      yes/no|602260074X|Dec 30, 2014|be the surface in...|         Y|                 yes|1.4199264E9|\n","|  open-ended|602260074X|Jul 13, 2014|how deep do the e...|       NaN|hi there not too ...|1.4052348E9|\n","|      yes/no|602260074X|May 21, 2014|can bottle of nai...|         ?|no we just try it...|1.4006556E9|\n","|  open-ended|602260074X|Feb 25, 2014|  what be the weight|       NaN|light box carry i...|1.3933152E9|\n","|  open-ended|602260074X| Dec 3, 2013|what be the dimen...|       NaN|i be not sure but...|1.3860576E9|\n","|  open-ended|602260074X|Jul 23, 2013|what be the tray ...|       NaN|there be 4 trays ...|1.3745628E9|\n","|  open-ended|7800558258| 18 days ago|how can i get a p...|       NaN|                good|        NaN|\n","|  open-ended|7800558258|Feb 28, 2015|i have use the pe...|       NaN|thank for your qu...|1.4251104E9|\n","|  open-ended|7800558258|May 28, 2014|goodnight crompre...|       NaN|i own this unit a...|1.4012604E9|\n","|      yes/no|7800558258|Jan 30, 2014|do it work for pe...|         N|no it do not the ...|1.3910688E9|\n","|      yes/no|7800558258| Nov 6, 2013|do it come with e...|         Y|                 yes|1.3837248E9|\n","|  open-ended|9788071813|Jun 10, 2014|how i know if the...|       NaN|why be you ask it...|1.4023836E9|\n","|  open-ended|9788071813|Apr 23, 2014|be this product i...|       NaN|yes it be perfect...|1.3982364E9|\n","|      yes/no|9788071813|Apr 23, 2014|be it in an origi...|         ?|s est en el paque...|1.3982364E9|\n","|  open-ended|B00004TUBL|Aug 15, 2013|how hard be it to...|       NaN|it be very easy t...|  1.37655E9|\n","|  open-ended|B00004TUBL| Dec 6, 2014|can i mount this ...|       NaN|i just use the co...|1.4178528E9|\n","|      yes/no|B00004TUBL|Jun 12, 2014|be the chamber ea...|         ?|i have the four c...|1.4025564E9|\n","|  open-ended|B00004TUBL|Oct 10, 2014|my spouse be worr...|       NaN|it open easy to c...|1.4129244E9|\n","+------------+----------+------------+--------------------+----------+--------------------+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["spark_df.show()"]},{"cell_type":"markdown","metadata":{"id":"sQvN8cKxbZux"},"source":["Les colonnes \"question\" et \"answer\" ont été prétraitées en convertissant le texte en minuscules, en supprimant les espaces en début et en fin de texte, en étendant les contractions, en remplaçant les représentations numériques spéciales, en supprimant les balises HTML, en supprimant la ponctuation et en lemmatisant les mots."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"zmT3def9zjSK","executionInfo":{"status":"ok","timestamp":1686486815850,"user_tz":-60,"elapsed":258,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}}},"outputs":[],"source":["spark_dff= spark_df.drop(\"answerType\",\"answerTime\",\"unixTime\",\"asin\")\n"]},{"cell_type":"markdown","metadata":{"id":"ld_k70o7bZuy"},"source":["Nous avez créé un nouveau DataFrame appelé spark_dff en supprimant les colonnes \"answerType\", \"answerTime\", \"unixTime\" et \"asin\" du DataFrame spark_df"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3018,"status":"ok","timestamp":1686486822585,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"Y3a_R4EgzjUm","outputId":"9528fe36-5510-46ab-900a-0d5a297e0525"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+--------------------+--------------------+\n","|questionType|            question|              answer|\n","+------------+--------------------+--------------------+\n","|      yes/no|can you fit make ...|yes it come with ...|\n","|      yes/no|can you move all ...|yes all the provi...|\n","|      yes/no|be the surface in...|                 yes|\n","|  open-ended|how deep do the e...|hi there not too ...|\n","|      yes/no|can bottle of nai...|no we just try it...|\n","|  open-ended|  what be the weight|light box carry i...|\n","|  open-ended|what be the dimen...|i be not sure but...|\n","|  open-ended|what be the tray ...|there be 4 trays ...|\n","|  open-ended|how can i get a p...|                good|\n","|  open-ended|i have use the pe...|thank for your qu...|\n","|  open-ended|goodnight crompre...|i own this unit a...|\n","|      yes/no|do it work for pe...|no it do not the ...|\n","|      yes/no|do it come with e...|                 yes|\n","|  open-ended|how i know if the...|why be you ask it...|\n","|  open-ended|be this product i...|yes it be perfect...|\n","|      yes/no|be it in an origi...|s est en el paque...|\n","|  open-ended|how hard be it to...|it be very easy t...|\n","|  open-ended|can i mount this ...|i just use the co...|\n","|      yes/no|be the chamber ea...|i have the four c...|\n","|  open-ended|my spouse be worr...|it open easy to c...|\n","+------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["spark_dff.show()"]},{"cell_type":"markdown","metadata":{"id":"7DhjawqKbZuz"},"source":["Le DataFrame spark_dff contient maintenant les colonnes \"questionType\", \"question\" et \"answer\" après avoir supprimé les colonnes spécifiées."]},{"cell_type":"markdown","metadata":{"id":"l-7LPPQ6bZuz"},"source":["### Embedding Creation :"]},{"cell_type":"markdown","metadata":{"id":"WGA8-uYobZuz"},"source":["Ce code utilise la classe Word2Vec du module pyspark.ml.feature pour entraîner un modèle Word2Vec sur les données de la colonne \"question\" du DataFrame split_df. "]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":55915,"status":"ok","timestamp":1686486904694,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"Vw6Qky0iAIye"},"outputs":[],"source":["from pyspark.ml.feature import Word2Vec\n","from pyspark.sql.functions import split\n","\n","# Split the 'question' column into an array of words\n","split_df = spark_dff.withColumn('question_words', split(spark_dff['question'], ' '))\n","\n","# Apply Word2Vec to the 'question_words' column\n","word2vec = Word2Vec(vectorSize=100, inputCol='question_words', outputCol='question_vectors')\n","word2vec_model = word2vec.fit(split_df)\n","\n","# Apply the Word2Vec model to transform the 'question_words' column\n","split_df = word2vec_model.transform(split_df)"]},{"cell_type":"markdown","metadata":{"id":"vJJ24yIEbZu0"},"source":["Le modèle Word2Vec est appliqué au DataFrame split_df en utilisant la méthode transform, ce qui génère une nouvelle colonne \"question_vectors\" contenant les vecteurs de mots calculés à partir des mots de la colonne \"question_words\"."]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2598,"status":"ok","timestamp":1686486913297,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"sqiDtooKDBn4","outputId":"1aab01fc-c164-4a10-ad0c-c536e6757a4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+--------------------+--------------------+--------------------+--------------------+\n","|questionType|            question|              answer|      question_words|    question_vectors|\n","+------------+--------------------+--------------------+--------------------+--------------------+\n","|      yes/no|can you fit make ...|yes it come with ...|[can, you, fit, m...|[0.02948325955205...|\n","|      yes/no|can you move all ...|yes all the provi...|[can, you, move, ...|[0.04757946970251...|\n","|      yes/no|be the surface in...|                 yes|[be, the, surface...|[0.10754237590091...|\n","|  open-ended|how deep do the e...|hi there not too ...|[how, deep, do, t...|[0.08646665779607...|\n","|      yes/no|can bottle of nai...|no we just try it...|[can, bottle, of,...|[0.09079277978162...|\n","|  open-ended|  what be the weight|light box carry i...|[what, be, the, w...|[-0.0132861584424...|\n","|  open-ended|what be the dimen...|i be not sure but...|[what, be, the, d...|[0.07267820090055...|\n","|  open-ended|what be the tray ...|there be 4 trays ...|[what, be, the, t...|[0.03919244249877...|\n","|  open-ended|how can i get a p...|                good|[how, can, i, get...|[-0.0249414243735...|\n","|  open-ended|i have use the pe...|thank for your qu...|[i, have, use, th...|[0.03593867900781...|\n","|  open-ended|goodnight crompre...|i own this unit a...|[goodnight, cromp...|[-0.0204769587489...|\n","|      yes/no|do it work for pe...|no it do not the ...|[do, it, work, fo...|[0.04652773322803...|\n","|      yes/no|do it come with e...|                 yes|[do, it, come, wi...|[-0.0059642628249...|\n","|  open-ended|how i know if the...|why be you ask it...|[how, i, know, if...|[-0.0024886139581...|\n","|  open-ended|be this product i...|yes it be perfect...|[be, this, produc...|[-0.0204272208023...|\n","|      yes/no|be it in an origi...|s est en el paque...|[be, it, in, an, ...|[-0.0207301825284...|\n","|  open-ended|how hard be it to...|it be very easy t...|[how, hard, be, i...|[-0.0111887200425...|\n","|  open-ended|can i mount this ...|i just use the co...|[can, i, mount, t...|[0.05592130501147...|\n","|      yes/no|be the chamber ea...|i have the four c...|[be, the, chamber...|[0.06692400503903...|\n","|  open-ended|my spouse be worr...|it open easy to c...|[my, spouse, be, ...|[0.04316162416297...|\n","+------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["split_df.show()"]},{"cell_type":"markdown","metadata":{"id":"VJnTlPO_bZu0"},"source":["Le DataFrame split_df contient maintenant deux nouvelles colonnes : \"question_words\", qui contient un tableau de mots de la colonne \"question\", et \"question_vectors\", qui contient les vecteurs de mots calculés à partir de ces mots à l'aide du modèle Word2Vec entraîné précédemment."]},{"cell_type":"markdown","metadata":{"id":"DfB8ILORbZu1"},"source":["### assembler_df"]},{"cell_type":"markdown","metadata":{"id":"N2i7nYFubZu1"},"source":["Le DataFrame assembler_df a été créé en sélectionnant les colonnes pertinentes pour le VectorAssembler :"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":331,"status":"ok","timestamp":1686486916072,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"HyE2byKvAnjf"},"outputs":[],"source":["# Select the relevant columns for the VectorAssembler\n","assembler_df = split_df.select('question_vectors', 'answer', 'questionType')\n"]},{"cell_type":"markdown","metadata":{"id":"xlfEdrFYbZu2"},"source":["Les colonnes sélectionnées sont \"question_vectors\" (vecteurs de mots de la question), \"answer\" (réponse) et \"questionType\" (type de question)."]},{"cell_type":"markdown","metadata":{"id":"Tw2Ty51CbZu2"},"source":["Le code utilise le **VectorAssembler** pour assembler les vecteurs de la colonne \"question_vectors\" dans une seule colonne de fonction appelée \"features\". Le nouveau DataFrame est nommé \"assembled_df\"."]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":1783,"status":"ok","timestamp":1686486947949,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"o_ExTpa2Axfi"},"outputs":[],"source":["# Assemble the vectors into a single feature column\n","from pyspark.ml.feature import VectorAssembler\n","assembler = VectorAssembler(inputCols=['question_vectors'], outputCol='features')\n","assembled_df = assembler.transform(assembler_df)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jd8UyshLbZu4","executionInfo":{"status":"ok","timestamp":1686486965212,"user_tz":-60,"elapsed":7931,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}},"outputId":"42dd76f2-3415-4de2-e3bf-d7bababce10d"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+------------+--------------------+\n","|    question_vectors|              answer|questionType|            features|\n","+--------------------+--------------------+------------+--------------------+\n","|[0.02948325955205...|yes it come with ...|      yes/no|[0.02948325955205...|\n","|[0.04757946970251...|yes all the provi...|      yes/no|[0.04757946970251...|\n","|[0.10754237590091...|                 yes|      yes/no|[0.10754237590091...|\n","|[0.08646665779607...|hi there not too ...|  open-ended|[0.08646665779607...|\n","|[0.09079277978162...|no we just try it...|      yes/no|[0.09079277978162...|\n","|[-0.0132861584424...|light box carry i...|  open-ended|[-0.0132861584424...|\n","|[0.07267820090055...|i be not sure but...|  open-ended|[0.07267820090055...|\n","|[0.03919244249877...|there be 4 trays ...|  open-ended|[0.03919244249877...|\n","|[-0.0249414243735...|                good|  open-ended|[-0.0249414243735...|\n","|[0.03593867900781...|thank for your qu...|  open-ended|[0.03593867900781...|\n","|[-0.0204769587489...|i own this unit a...|  open-ended|[-0.0204769587489...|\n","|[0.04652773322803...|no it do not the ...|      yes/no|[0.04652773322803...|\n","|[-0.0059642628249...|                 yes|      yes/no|[-0.0059642628249...|\n","|[-0.0024886139581...|why be you ask it...|  open-ended|[-0.0024886139581...|\n","|[-0.0204272208023...|yes it be perfect...|  open-ended|[-0.0204272208023...|\n","|[-0.0207301825284...|s est en el paque...|      yes/no|[-0.0207301825284...|\n","|[-0.0111887200425...|it be very easy t...|  open-ended|[-0.0111887200425...|\n","|[0.05592130501147...|i just use the co...|  open-ended|[0.05592130501147...|\n","|[0.06692400503903...|i have the four c...|      yes/no|[0.06692400503903...|\n","|[0.04316162416297...|it open easy to c...|  open-ended|[0.04316162416297...|\n","+--------------------+--------------------+------------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["assembled_df.show()"]},{"cell_type":"markdown","metadata":{"id":"XuBhRkC3bZu4"},"source":["Le DataFrame résultant contient les colonnes d'origine ainsi que la colonne \"features\" qui contient les vecteurs assemblés."]},{"cell_type":"markdown","metadata":{"id":"kmaIW7gRbZu5"},"source":["### indexed_df"]},{"cell_type":"markdown","metadata":{"id":"Gh9IU86kbZu5"},"source":["Le code utilise le **StringIndexer** pour indexer la colonne 'questionType' et crée une nouvelle colonne 'label' qui contient les valeurs indexées."]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1801,"status":"ok","timestamp":1686486996528,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"LtqvXHWFEMFF"},"outputs":[],"source":["# Index the 'questionType' column\n","from pyspark.ml.feature import StringIndexer\n","indexer = StringIndexer(inputCol='questionType', outputCol='label')\n","indexed_df = indexer.fit(assembled_df).transform(assembled_df)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4D8lUyQGbZu6","executionInfo":{"status":"ok","timestamp":1686487008913,"user_tz":-60,"elapsed":7232,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}},"outputId":"91773165-a792-47a1-b73f-b370aa54330e"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+------------+--------------------+-----+\n","|    question_vectors|              answer|questionType|            features|label|\n","+--------------------+--------------------+------------+--------------------+-----+\n","|[0.02948325955205...|yes it come with ...|      yes/no|[0.02948325955205...|  1.0|\n","|[0.04757946970251...|yes all the provi...|      yes/no|[0.04757946970251...|  1.0|\n","|[0.10754237590091...|                 yes|      yes/no|[0.10754237590091...|  1.0|\n","|[0.08646665779607...|hi there not too ...|  open-ended|[0.08646665779607...|  0.0|\n","|[0.09079277978162...|no we just try it...|      yes/no|[0.09079277978162...|  1.0|\n","|[-0.0132861584424...|light box carry i...|  open-ended|[-0.0132861584424...|  0.0|\n","|[0.07267820090055...|i be not sure but...|  open-ended|[0.07267820090055...|  0.0|\n","|[0.03919244249877...|there be 4 trays ...|  open-ended|[0.03919244249877...|  0.0|\n","|[-0.0249414243735...|                good|  open-ended|[-0.0249414243735...|  0.0|\n","|[0.03593867900781...|thank for your qu...|  open-ended|[0.03593867900781...|  0.0|\n","|[-0.0204769587489...|i own this unit a...|  open-ended|[-0.0204769587489...|  0.0|\n","|[0.04652773322803...|no it do not the ...|      yes/no|[0.04652773322803...|  1.0|\n","|[-0.0059642628249...|                 yes|      yes/no|[-0.0059642628249...|  1.0|\n","|[-0.0024886139581...|why be you ask it...|  open-ended|[-0.0024886139581...|  0.0|\n","|[-0.0204272208023...|yes it be perfect...|  open-ended|[-0.0204272208023...|  0.0|\n","|[-0.0207301825284...|s est en el paque...|      yes/no|[-0.0207301825284...|  1.0|\n","|[-0.0111887200425...|it be very easy t...|  open-ended|[-0.0111887200425...|  0.0|\n","|[0.05592130501147...|i just use the co...|  open-ended|[0.05592130501147...|  0.0|\n","|[0.06692400503903...|i have the four c...|      yes/no|[0.06692400503903...|  1.0|\n","|[0.04316162416297...|it open easy to c...|  open-ended|[0.04316162416297...|  0.0|\n","+--------------------+--------------------+------------+--------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["indexed_df.show()"]},{"cell_type":"markdown","metadata":{"id":"0BlD4GEJbZu6"},"source":["Le DataFrame résultant contient les colonnes d'origine ainsi que la colonne 'label' qui contient les valeurs indexées pour la colonne 'questionType'."]},{"cell_type":"markdown","metadata":{"id":"L8l-BsrybZu6"},"source":["### Data Splitting :"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":430,"status":"ok","timestamp":1686487050602,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"ZsmSFw4ZAxog"},"outputs":[],"source":["# Split the data into training and testing sets\n","train_data, test_data = indexed_df.randomSplit([0.8, 0.2], seed=42)"]},{"cell_type":"markdown","metadata":{"id":"U66Q8t49bZu7"},"source":["Le code divise les données en ensembles d'entraînement et de test à l'aide de la méthode **randomSplit**. Il utilise un ratio de 80% pour l'ensemble d'entraînement et de 20% pour l'ensemble de test. La graine (seed) est fixée à 42 pour assurer la reproductibilité des résultats."]},{"cell_type":"markdown","metadata":{"id":"tPElFtK9bZu7"},"source":["### Model Training :"]},{"cell_type":"markdown","metadata":{"id":"f72LmODIbZu8"},"source":["Le code utilise un modèle **RandomForestClassifier** pour l'apprentissage. Le modèle est configuré avec les colonnes featuresCol='features' (contenant les caractéristiques des données) et labelCol='label' (contenant les étiquettes des données). Cela signifie que le modèle utilisera les caractéristiques des données pour prédire les étiquettes."]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":233,"status":"ok","timestamp":1686487072584,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"St4FNrCqAxry"},"outputs":[],"source":["# Train the model\n","from pyspark.ml.classification import RandomForestClassifier\n","rf = RandomForestClassifier(featuresCol='features', labelCol='label')"]},{"cell_type":"markdown","metadata":{"id":"ohZzXCVebZu9"},"source":["### Pipeline :"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":162567,"status":"ok","timestamp":1686487263972,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"k-akf3gHAxyF"},"outputs":[],"source":["from pyspark.ml import Pipeline\n","# Create a pipeline\n","pipeline = Pipeline(stages=[rf])\n","\n","\n","# Train the model\n","model = pipeline.fit(train_data)"]},{"cell_type":"markdown","metadata":{"id":"MIRugAD7bZu9"},"source":["Dans ce code nous avons créé un pipeline avec une seule étape contenant le modèle RandomForestClassifier. Un pipeline est utilisé pour chaîner différentes étapes de traitement des données et d'apprentissage automatiquement."]},{"cell_type":"markdown","metadata":{"id":"tG7ANmUEbZu9"},"source":["### Predictions :"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":827,"status":"ok","timestamp":1686487269804,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"m6Jl7KCuBg62"},"outputs":[],"source":["# Make predictions on the test data\n","predictions = model.transform(test_data)"]},{"cell_type":"code","source":["predictions.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrAElqM7eZRm","executionInfo":{"status":"ok","timestamp":1686487310121,"user_tz":-60,"elapsed":20171,"user":{"displayName":"Doha ben","userId":"15369879026236646516"}},"outputId":"d115d229-a463-42b7-aa6b-34e684343f76"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+------------+--------------------+-----+--------------------+--------------------+----------+\n","|    question_vectors|              answer|questionType|            features|label|       rawPrediction|         probability|prediction|\n","+--------------------+--------------------+------------+--------------------+-----+--------------------+--------------------+----------+\n","|[-0.2282457351684...|yes there be a sl...|  open-ended|[-0.2282457351684...|  0.0|[13.0689151309662...|[0.65344575654831...|       0.0|\n","|[-0.2151029556989...|although the bott...|  open-ended|[-0.2151029556989...|  0.0|[6.69880956969952...|[0.33494047848497...|       1.0|\n","|[-0.2119010519236...|            no manly|  open-ended|[-0.2119010519236...|  0.0|[12.1343807425312...|[0.60671903712656...|       0.0|\n","|[-0.1856990994678...|it be eau de colo...|  open-ended|[-0.1856990994678...|  0.0|[14.8017971491586...|[0.74008985745793...|       0.0|\n","|[-0.1841507721692...|have naturally si...|      yes/no|[-0.1841507721692...|  1.0|[4.12743377858892...|[0.20637168892944...|       1.0|\n","|[-0.1841507721692...|                 yes|      yes/no|[-0.1841507721692...|  1.0|[4.12743377858892...|[0.20637168892944...|       1.0|\n","|[-0.1785912923514...|yes free ship wit...|      yes/no|[-0.1785912923514...|  1.0|[11.1047998831670...|[0.55523999415835...|       0.0|\n","|[-0.1771728713065...|it come inside a ...|  open-ended|[-0.1771728713065...|  0.0|[12.6064412670489...|[0.63032206335244...|       0.0|\n","|[-0.1633029585704...|at the moment bec...|  open-ended|[-0.1633029585704...|  0.0|[12.8479418116941...|[0.64239709058470...|       0.0|\n","|[-0.1633029585704...|at the moment bec...|  open-ended|[-0.1633029585704...|  0.0|[12.8479418116941...|[0.64239709058470...|       0.0|\n","|[-0.1633029585704...|at the moment bec...|  open-ended|[-0.1633029585704...|  0.0|[12.8479418116941...|[0.64239709058470...|       0.0|\n","|[-0.1632246430963...|sulfate be lather...|  open-ended|[-0.1632246430963...|  0.0|[10.6325965592371...|[0.53162982796185...|       0.0|\n","|[-0.1609414406120...|it be eau de toil...|      yes/no|[-0.1609414406120...|  1.0|[7.19823018441836...|[0.35991150922091...|       1.0|\n","|[-0.1607976928353...|the dominate note...|  open-ended|[-0.1607976928353...|  0.0|[13.7576442626059...|[0.68788221313029...|       0.0|\n","|[-0.1600766384508...|i would say no as...|      yes/no|[-0.1600766384508...|  1.0|[5.36973495385411...|[0.26848674769270...|       1.0|\n","|[-0.1594462562352...|i would love to a...|      yes/no|[-0.1594462562352...|  1.0|[8.20288249322404...|[0.41014412466120...|       1.0|\n","|[-0.1568396463990...|they change the s...|  open-ended|[-0.1568396463990...|  0.0|[12.8395407932550...|[0.64197703966275...|       0.0|\n","|[-0.1568396463990...|they change the s...|  open-ended|[-0.1568396463990...|  0.0|[12.8395407932550...|[0.64197703966275...|       0.0|\n","|[-0.1561466529965...|yes the ingredien...|      yes/no|[-0.1561466529965...|  1.0|[4.27538586470165...|[0.21376929323508...|       1.0|\n","|[-0.1529178962111...|i be out of the p...|      yes/no|[-0.1529178962111...|  1.0|[4.27538586470165...|[0.21376929323508...|       1.0|\n","+--------------------+--------------------+------------+--------------------+-----+--------------------+--------------------+----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"mxjnikAhbZu-"},"source":["Le modèle utilise les caractéristiques (features) extraites des données de test pour prédire les étiquettes correspondantes. Les prédictions sont ensuite ajoutées comme colonne \"prediction\" dans le dataframe \"predictions\"."]},{"cell_type":"markdown","metadata":{"id":"5CA97S_ObZu-"},"source":["### Model Evaluation :"]},{"cell_type":"markdown","metadata":{"id":"pPtMReW0bZu-"},"source":[" la précision (accuracy) du modèle sur les données de test."]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37616,"status":"ok","timestamp":1686487406368,"user":{"displayName":"Doha ben","userId":"15369879026236646516"},"user_tz":-60},"id":"wzAOhSeQEpCx","outputId":"cfad91d2-83a5-495c-9fe7-3811edb4f86f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 75.07%\n"]}],"source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"]},{"cell_type":"markdown","metadata":{"id":"gKLo1g3XbZu_"},"source":[" la précision obtenue est de 75,07%. Cela signifie que le modèle prédit correctement la classe de l'objet dans environ 75,73% des cas sur les données de test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QXm4TnseF1Pu"},"outputs":[],"source":["predictions.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}